{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4d2efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf8155d",
   "metadata": {},
   "source": [
    "**The Document Location**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623601b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfPath = \"python_fundamentals.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb8a786",
   "metadata": {},
   "source": [
    "**Function for loading the file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f796531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadFile(path):\n",
    "    reader = PdfReader(path)\n",
    "    allTexts = \"\"\n",
    "\n",
    "    for page in reader.pages:\n",
    "        text = page.extract_text()\n",
    "        if text:\n",
    "            allTexts += text + \"\\n\"\n",
    "\n",
    "    return allTexts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057172d3",
   "metadata": {},
   "source": [
    "**Splitting data into chunks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3d960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitIntoChunks(text, chunkSize = 300, overlap = 50):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "\n",
    "    text_length = len(text)\n",
    "\n",
    "    while start < text_length:\n",
    "        end = start + chunkSize\n",
    "        chunk = text[start:end]\n",
    "        chunks.append(chunk)\n",
    "        start = end - overlap\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67634248",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = loadFile(pdfPath)\n",
    "print(\"total characters : \",len(text))\n",
    "\n",
    "chunks = splitIntoChunks(text)\n",
    "print(\"total chunks created : \",len(chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b519a296",
   "metadata": {},
   "source": [
    "**Loading Embedding Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e005d220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196af7a9",
   "metadata": {},
   "source": [
    "**ChromaDB setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0689dd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "# creating chromadb instance which will store all chunks and embeddings in it\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "collection  = chroma_client.create_collection(name = \"pdf_readers\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafd0ced",
   "metadata": {},
   "source": [
    "**Inserting data into CHROMADB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29de9b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i , chunk in enumerate(chunks):\n",
    "    emb = model.encode([chunk])[0].tolist()\n",
    "    collection.add(\n",
    "        documents = [chunk],\n",
    "        embeddings = [emb],\n",
    "        ids = [f\"chunk-{i}\"]\n",
    "    )\n",
    "\n",
    "print(\"vector db is ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3ca0d3",
   "metadata": {},
   "source": [
    "### Integrating LLM through Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3a7721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def runLLM(prompt):\n",
    "    response = ollama.generate(\n",
    "        model = \"tinyllama\", # you have to pull \"ollama pull tinyllama\" on your local ollama terminal\n",
    "        prompt = prompt\n",
    "    )\n",
    "    return response[\"response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc42e68b",
   "metadata": {},
   "source": [
    "**RAG Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb8f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "\n",
    "    print(\"The Question is : \",query)\n",
    "\n",
    "    # step1 : embed the query\n",
    "    query_emb = model.encode([query])[0].tolist()\n",
    "\n",
    "    # step2 : retrieve chunks\n",
    "    results = collection.query(\n",
    "        query_embeddings = [query_emb],# Compares it with every stored chunk embedding, Uses cosine similarity, Finds closest vectors\n",
    "\n",
    "        n_results = 2   # top 2 similar matches\n",
    "    )\n",
    "\n",
    "    chunks = results[\"documents\"][0]\n",
    "    context = \"\\n\\n\".join(chunks) # the only knowledge we will give to llm to think for the query\n",
    "\n",
    "\n",
    "    # step3 : Building the prompt\n",
    "    prompt = f\"\"\"Use ONLY the context below to answer the question.CONTEXT:{context}QUESTION: {query}If answer is not in the context, say: \"I don't know\".\"\"\"\n",
    "\n",
    "\n",
    "    # step4: run llm \n",
    "    answer = runLLM(prompt)\n",
    "    print(\"Answer:\\n\")\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0b82d4",
   "metadata": {},
   "source": [
    "**Asking question from user and pass it to the LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ae88d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "userQuery = input(\"What's your question ?\")\n",
    "rag(userQuery)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
